---
title: "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective."
collection: talks
type: "Invited Talk"
permalink: /talks/2022-06-12-talk-4
venue: "AI TIME"
date: 2022-06-12
location: "Sydney, Australia"
---

We formulate the asymptotic behaviors of GNTK in the large depth, 
which enables us to reveal the dropping trainability of wide and deep GCNs at an exponential rate in the optimization process. 
Additionally, we extend our theoretical framework to analyze residual connection-based techniques, 
which are found to be merely able to mitigate the exponential decay of trainability mildly. 
Inspired by our theoretical insights on trainability, we propose Critical DropEdge, 
a connectivity-aware and graph-adaptive sampling method, to alleviate the exponential decay problem more fundamentally.
