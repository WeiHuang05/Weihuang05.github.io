---
title: Welcome to Wei Huang's Homepage
---

I am a Research Scientist in the [Deep Learning Theory Team](https://www.riken.jp/en/research/labs/aip/generic_tech/deep_learn_theory/) at [RIKEN Center for Advanced Intelligence Project (AIP)](https://www.riken.jp/en/research/labs/aip/), working with [Prof. Taiji Suzuki](http://ibis.t.u-tokyo.ac.jp/suzuki/). Prior to this role, I was as a Postdoctoral Researcher in the same team. Before, I was working as a research associate advised by [Dr. Xin Cao](https://research.unsw.edu.au/people/dr-xin-cao) at UNSW and working with [A/Prof. Jie Yin](https://www.sydney.edu.au/business/about/our-people/academic-staff/jie-yin.html) on graph neural network at USYD.

Dr. Huang obtained his Ph.D. degree at Faculty of Engineering and Information Technology, University of Technology Sydney working with [Prof. Richard Xu](https://profiles.uts.edu.au/YiDa.Xu). I obtained my Master degree at the department of modern Physics, University of Science and Technology of China, supervised by [Prof. Youjin Deng](http://staff.ustc.edu.cn/~yjdeng/).

I maintain a comprehensive and popular blog on the latest Deep Learning Theory works on [Zhihu](https://www.zhihu.com/people/huang-wei-17-47-45) and a feature learning theory reading list on [Github](https://github.com/WeiHuang05/Awesome-Feature-Learning-in-Deep-Learning-Thoery).

Please feel free to contact me if you want to cooperate or discuss with me (weihuang[dot]uts[at]gmail[dot]com) on deep learning theory and its application. 

My office is located at the [University of Tokyo](https://www.u-tokyo.ac.jp/ja/index.html), Hongo Campus. If you would like to reach out, please don't hesitate to do so.

### Research Interest

* Theoretically understanding deep learning and large foundation modal from expressivity, trainability, and generalization.
  
  Feature Learning; Implicit Regularization/Bias; Neural Tangent Kernel;

* Applications powered by deep learning theory: 

  Large Foundation Model, Graph Neural Networks; Computer Vision 
  

### News


* 05/2024 One paper is accepted by KDD 2024 Research Track, [The Heterophily Snowflake Hypothesis: Training and Empowering GNN for Heterophilic Graphs](https://arxiv.org/abs/2406.12539).

* 05/2024 I will be attending [ICLR 2024](https://iclr.cc/) from 06/05/2024 to 12/05/2024 in Vienna. Feel free have a chat if you're there.

* 05/2024 Two papers are accepted by ICML 2024. [Diffusion Models Demand Contrastive Guidance for Adversarial Purification to Advance](https://openreview.net/forum?id=2NUGeV64y2); [Provably Neural Active Learning Succeeds via Prioritizing Perplexing Samples](https://arxiv.org/pdf/2406.03944v1)

* 02/2024 One paper is accepted by CVPR 2024, [Global and Local Prompts Cooperation via Optimal Transport for Federated Learning](https://arxiv.org/abs/2403.00041) 

* 01/2024 Two papers are accepted by ICLR 2024, [Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory](https://openreview.net/forum?id=EcetCr4trp); [Graph Lottery Ticket Automated](https://openreview.net/forum?id=nmBjBZoySX) 

* 12/2023 I will be attending [NeurIPS 2023](https://nips.cc/) from 10/12/2023 to 17/12/2023 at the New Orleans Ernest N. Morial Convention Center. Feel free have a chat if you're there.

* 12/2023 One paper is accepted by IEEE Transactions on Image Processing, [DMMG: Dual Min-Max Games for Self-Supervised Skeleton-Based Action Recognition](https://ieeexplore.ieee.org/document/10348505)

* 10/2023 I will be attending [IBIS2023](https://ibisml.org/ibis2023/cfp/) from 29/10/2023 to 01/11/2023 in Kitakyushu. Feel free have a chat if you're there.

* 09/2023 Three papers are accepted by NeurIPS 2023, [Understanding and Improving Feature Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2304.11327); [Analyzing Generalization of Neural Networks through Loss Path Kernels](https://openreview.net/pdf?id=8Ba7VJ7xiM);  [Fed-CO_2: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning](https://arxiv.org/abs/2312.13923); 

* 08/2023 One paper is accepted by Transactions on Machine Learning Research, [Single-Pass Contrastive Learning Can Work for Both Homophilic and Heterophilic Graph](https://openreview.net/pdf?id=244KePn09i)

* 08/2023 I will be attending [ICIAM 2023](https://iciam2023.org/registered_data?id=00088) at Waseda University, Tokyo. Feel free to have a chat if you're there.

* 07/2023 I had the privilege of giving a contributed talk at the [ICML 2023 workshop on High-Dimensional Learning Dynamics](https://sites.google.com/view/hidimlearning/home?authuser=0) in Honolulu, Hawaii. It was a great experience sharing my [work](https://arxiv.org/abs/2306.13926) with researchers. Please find my [slides](https://github.com/WeiHuang05/Weihuang05.github.io/blob/main/files/ICML_HiLD_Graph_feature_Weihuang.pdf) here.

* 06/2023 One paper is accepted by High-dimensional Learning Dynamics Workshop (ICML) 2023, [Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective](https://arxiv.org/abs/2306.13926)

* 05/2023 One paper is accepted by Transactions on Machine Learning Research, [Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection](https://openreview.net/pdf?id=nEX2q5B2RQ)

* 05/2023 One paper is accepted by AutoML 2023. [No Free Lunch in Neural Architectures? A Joint Analysis of Expressivity, Convergence, and Generalization]()

* 03/2023 One paper is accepted by ICLR 2023 workshop, [Towards Understanding Feature Learning in Out-of-Distribution Generalization
](https://arxiv.org/abs/2304.11327)

* 11/2022 I arrived in Tokyo, Japan! 

* 09/2022 Four papers are accepted by NeurIPS 2022, [Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis](https://arxiv.org/abs/2205.05662); [Deep Active Learning by Leveraging Training Dynamics](https://arxiv.org/abs/2110.08611); [Interpreting Operation Selection in Differentiable Architecture Search: A Perspective from Influence-Directed Explanations](https://openreview.net/forum?id=MPARWTuMiPh); [Weighted Mutual Learning with Diversity-Driven Model Compression](https://proceedings.neurips.cc/paper_files/paper/2022/file/4b25c000967af9036fb9b207b198a626-Paper-Conference.pdf) 

* 08/2022 One paper [Pruning graph neural networks by evaluating edge properties](https://www.sciencedirect.com/science/article/pii/S0950705122009406) is accepted by Knowledge-Based Systems journal (IF: 8.664)

* 05/2022 I am invited to serve as a reviewer for ICLR-2023 

* 03/2022 I am invited to serve as a reviewer for NeurIPS-2022 

* 01/2022 Two papers are accepted by ICLR 2022, [Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective](https://arxiv.org/abs/2103.03113); [Auto-scaling Vision Transformers without Training](https://openreview.net/pdf?id=H94a1_Pyr-6)

* 12/2021 I am invited to serve as a reviewer for ICML-2022 

* 11/2021 I am invited to serve as a reviewer for CVPR-2022 

* 09/2021 One paper is accepted by NeurIPS 2021, [On the Equivalence between Neural Network and Support Vector Machine](https://arxiv.org/abs/2111.06063)

* 07/2021 I am invited to serve as a Senior Program Committee member for AAAI-2022 

* 06/2021 I am invited to serve as a reviewer for ICLR-2022 

* 04/2021 One paper is accepted by IJCAI 2021, [On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization](https://arxiv.org/abs/2004.05867)

* 03/2021 I am invited to serve as a reviewer for NeurIPS-2021 

* 12/2020 I am invited to serve as a reviewer for ICML-2021 

<a href="https://clustrmaps.com/site/1bvzb"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=2P20-QcaTNFo4oRUSbUIDNvbba1-oYtex2xzmbuuEqU&cl=ffffff" /></a>
