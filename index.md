---
title: Welcome to Wei Huang's Homepage
---

I am currently a research fellow at Deep Learning Theory Team of RIKEN AIP, working with [A/Prof. Taiji Suzuki](http://ibis.t.u-tokyo.ac.jp/suzuki/). Before, I was working as a research associate advised by [Dr. Xin Cao](https://research.unsw.edu.au/people/dr-xin-cao) at UNSW and working with [A/Prof. Jie Yin](https://www.sydney.edu.au/business/about/our-people/academic-staff/jie-yin.html) on graph neural network at USYD.

Dr. Huang obtained his Ph.D. degree at Faculty of Engineering and Information Technology, University of Technology Sydney working with [Prof. Richard Xu](https://profiles.uts.edu.au/YiDa.Xu). I obtained my Master degree at the department of modern Physics, University of Science and Technology of China, supervised by [Prof. Youjin Deng](http://staff.ustc.edu.cn/~yjdeng/).

I keep a comprehensive and popular blog on the latest Deep Learning Theory works on [Zhihu](https://www.zhihu.com/people/huang-wei-17-47-45).

Please feel free to contact me if you want to cooperate or discuss with me (weihuang[dot]uts[at]gmail[dot]com) on deep learning theory and its application. 

My office is located at the [University of Tokyo](https://www.u-tokyo.ac.jp/ja/index.html), Hongo Campus. If you would like to reach out, please don't hesitate to do so.

### Research Interest

* Theoretically understanding deep learning from expressivity, trainability, and generalization.
  
  Feature Learning; Implicit Regularization/Bias; Neural Tangent Kernel;

* Applications powered by deep learning: 

  Large Foundation Model, Graph Neural Networks; Computer Vision (Neural Architecture Search)
  
  

### News

* 10/2023 I will be attending [IBIS2023](https://ibisml.org/ibis2023/cfp/) from 29/10/2023 to 01/11/2023 in Kitakyushu. Feel free have a chat if you're there.

* 09/2023 Three papers are accepted by NeurIPS 2023 (CORE A*, CCF A), [Understanding and Improving Feature Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2304.11327); Analyzing Generalization of Neural Networks through Loss Path Kernels;  Fed-CO_2: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning; 

* 08/2023 One paper is accepted by Transactions on Machine Learning Research, [Single-Pass Contrastive Learning Can Work for Both Homophilic and Heterophilic Graph](https://openreview.net/pdf?id=244KePn09i)

* 08/2023 I will be attending [ICIAM 2023](https://iciam2023.org/registered_data?id=00088) at Waseda University, Tokyo. Feel free to have a chat if you're there.

* 07/2023 I had the privilege of giving a contributed talk at the [ICML 2023 workshop on High-Dimensional Learning Dynamics](https://sites.google.com/view/hidimlearning/home?authuser=0) in Honolulu, Hawaii. It was a great experience sharing my [work](https://arxiv.org/abs/2306.13926) with researchers. Please find my [slides](https://github.com/WeiHuang05/Weihuang05.github.io/blob/main/files/ICML_HiLD_Graph_feature_Weihuang.pdf) here.

* 06/2023 One paper is accepted by High-dimensional Learning Dynamics Workshop (ICML) 2023, [Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective](https://arxiv.org/abs/2306.13926)

* 05/2023 One paper is accepted by Transactions on Machine Learning Research, [Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection](https://openreview.net/pdf?id=nEX2q5B2RQ)

* 05/2023 One paper is accepted by AutoML 2023. [No Free Lunch in Neural Architectures? A Joint Analysis of Expressivity, Convergence, and Generalization]()

* 03/2023 One paper is accepted by ICLR 2023 workshop, [Towards Understanding Feature Learning in Out-of-Distribution Generalization
](https://arxiv.org/abs/2304.11327)

* 11/2022 I arrived in Tokyo, Japan! 

* 09/2022 Four papers are accepted by NeurIPS 2022 (CORE A*, CCF A), [Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis](https://arxiv.org/abs/2205.05662); [Deep Active Learning by Leveraging Training Dynamics](https://arxiv.org/abs/2110.08611); [Interpreting Operation Selection in Differentiable Architecture Search: A Perspective from Influence-Directed Explanations](https://openreview.net/forum?id=MPARWTuMiPh) 

* 08/2022 One paper is accepted by Knowledge-Based Systems journal (IF: 8.664)

* 05/2022 I am invited to serve as a reviewer for ICLR-2023 (CORE A*) 

* 03/2022 I am invited to serve as a reviewer for NeurIPS-2022 (CORE A*, CCF A) 

* 01/2022 Two papers are accepted by ICLR 2022 (CORE A*), [Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective](https://arxiv.org/abs/2103.03113); [Auto-scaling Vision Transformers without Training](https://openreview.net/pdf?id=H94a1_Pyr-6)

* 12/2021 I am invited to serve as a reviewer for ICML-2022 (CORE A*)

* 11/2021 I am invited to serve as a reviewer for CVPR-2022 (CORE A*)

* 09/2021 One paper is accepted by NeurIPS 2021 (CORE A*), [On the Equivalence between Neural Network and Support Vector Machine](https://arxiv.org/abs/2111.06063)

* 07/2021 I am invited to serve as a Senior Program Committee member for AAAI-2022 (CORE A*) 

* 06/2021 I am invited to serve as a reviewer for ICLR-2022 (CORE A*) 

* 04/2021 One paper is accepted by IJCAI 2021 (CORE A*, CCF A), [On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization](https://arxiv.org/abs/2004.05867)

* 03/2021 I am invited to serve as a reviewer for NeurIPS-2021 (CORE A*, CCF A) 

* 12/2020 I am invited to serve as a reviewer for ICML-2021 (CORE A*, CCF A)

<a href="https://clustrmaps.com/site/1bvzb"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=2P20-QcaTNFo4oRUSbUIDNvbba1-oYtex2xzmbuuEqU&cl=ffffff" /></a>
