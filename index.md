---
title: Welcome to Wei Huang's Homepage
---

I am currently research fellow at Deep Learning Theory Team of RIKEN AIP, working with [A/Prof. Taiji Suzuki](http://ibis.t.u-tokyo.ac.jp/suzuki/). Before, I was working as a research associate advised by [Dr. Xin Cao](https://research.unsw.edu.au/people/dr-xin-cao) at UNSW and working with [A/Prof. Jie Yin](https://www.sydney.edu.au/business/about/our-people/academic-staff/jie-yin.html) on graph neural network at USYD.

Dr. Huang obtained his Ph.D. degree at Faculty of Engineering and Information Technology, University of Technology Sydney working with [A/Prof. Richard Xu](https://profiles.uts.edu.au/YiDa.Xu). I obtained my Master degree at the department of modern Physics, University of Science and Technology of China, supervised by [Prof. Youjin Deng](http://staff.ustc.edu.cn/~yjdeng/).

I also keep a comprehensive and popular blog on the latest Deep Learning Theory works on [Zhihu](https://www.zhihu.com/people/huang-wei-17-47-45).

Please feel free to contact me if you want to cooperate or discuss with me (weihuang[dot]uts[at]gmail[dot]com) on deep learning theory and its application. 

### Research Interest

* Theoretical understanding of LLM

* Theoretically understanding deep learning from expressivity, trainability, and generalization.
  
  Feature Learning; Implicit Regularization/Bias; Neural Tangent Kernel;

* Applications powered by deep learning: 

  Graph Neural Networks; Computer Vision (Neural Architecture Search)
  
  

### News

* 06/2023 One paper is accepted by High-dimensional Learning Dynamics Workshop (ICML) 2023, [Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective]()

* 05/2023 One paper is accepted by Transactions on Machine Learning Research, [Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection](https://openreview.net/pdf?id=nEX2q5B2RQ)

* 05/2023 One paper is accepted by AutoML 2023. [No Free Lunch in Neural Architectures? A Joint Analysis of Expressivity, Convergence, and Generalization]()

* 03/2023 One paper is accepted by ICLR 2023 workshop, [Towards Understanding Feature Learning in Out-of-Distribution Generalization
](https://arxiv.org/abs/2304.11327)

* 11/2022 I arrived in Tokyo, Japan! 

* 09/2022 Four papers are accepted by NeurIPS 2022 (CORE A*, CCF A), [Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis](https://arxiv.org/abs/2205.05662); [Deep Active Learning by Leveraging Training Dynamics](https://arxiv.org/abs/2110.08611); [Interpreting Operation Selection in Differentiable Architecture Search: A Perspective from Influence-Directed Explanations](https://openreview.net/forum?id=MPARWTuMiPh) 

* 08/2022 One paper is accepted by Knowledge-Based Systems journal (IF: 8.664)

* 05/2022 I am invited to serve as a reviewer for ICLR-2023 (CORE A*) 

* 03/2022 I am invited to serve as a reviewer for NeurIPS-2022 (CORE A*, CCF A) 

* 01/2022 Two papers are accepted by ICLR 2022 (CORE A*), [Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective](https://arxiv.org/abs/2103.03113); [Auto-scaling Vision Transformers without Training](https://openreview.net/pdf?id=H94a1_Pyr-6)

* 12/2021 I am invited to serve as a reviewer for ICML-2022 (CORE A*)

* 11/2021 I am invited to serve as a reviewer for CVPR-2022 (CORE A*)

* 09/2021 One paper is accepted by NeurIPS 2021 (CORE A*), [On the Equivalence between Neural Network and Support Vector Machine](https://arxiv.org/abs/2111.06063)

* 07/2021 I am invited to serve as a Senior Program Committee member for AAAI-2022 (CORE A*) 

* 06/2021 I am invited to serve as a reviewer for ICLR-2022 (CORE A*) 

* 04/2021 One paper is accepted by IJCAI 2021 (CORE A*, CCF A), [On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization](https://arxiv.org/abs/2004.05867)

* 03/2021 I am invited to serve as a reviewer for NeurIPS-2021 (CORE A*, CCF A) 

* 12/2020 I am invited to serve as a reviewer for ICML-2021 (CORE A*, CCF A) 

